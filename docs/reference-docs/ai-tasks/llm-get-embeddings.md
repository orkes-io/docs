---
sidebar_position: 4
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# LLM Get Embeddings

A system task to get the numerical vector representations of words, phrases, sentences, or documents that have been previously learned or generated by the model. Unlike the process of generating embeddings ([LLM Generate Embeddings](/content/reference-docs/ai-tasks/llm-generate-embeddings) task), which involves creating vector representations from input data, this task deals with the retrieval of pre-existing embeddings for efficient and rapid access. This task is valuable when you have already computed and stored embeddings for various text elements and want to use them without the need for regeneration.

## Definitions

```json
{
"name": "llm_get_embeddings_task",
"taskReferenceName": "llm_get_embeddings_task_ref",
"inputParameters": {
"vectorDB": "pineconedb",
"namespace": "myNewModel",
"index": "test",
"embeddings": "${llm_generate_embeddings_task_ref.output}"
},
"type": "LLM_GET_EMBEDDINGS"
}
```

## Input Parameters

| Attribute | Description | 
| --------- | ----------- | 
| vectorDB | Choose the required vector database.<br/><br/>**Note**:If you havenâ€™t configured the vector database on your Orkes console, navigate to the Integrations tab and configure your required provider. Refer to this doc on [how to integrate Vector Databases with Orkes console](/content/category/integrations/vector-databases). |
| namespace | Choose from the available namespace configured within the chosen vector database.<br/><br/>Namespaces are separate isolated environments within the database to manage and organize vector data effectively.<br/><br/>**Note**:Namespace field is applicable only for Pinecone integration and is not applicable to Weaviate integration.|
| index | Choose the index in your vector database where indexed text or data was stored.<br/><br/> **Note:**For Weaviate integration, this field refers to the class name, while in Pinecone integration, it denotes the index name itself.|
| embeddings | Choose the embeddings from which the stored data is to be retrieved. |

## Output Parameters

| Attribute | Description | 
| --------- | ----------- | 
| score | Represents a value that quantifies the degree of likeness between a specific item and a query vector, facilitating the ranking and ordering of results. Higher scores denote a stronger resemblance or relevance of a data point to the query vector.|
| docId | Displays the docId from where the text is queried.|

## Examples

<Tabs>
<TabItem value="UI" label="UI" className="paddedContent">

<div className="row">
<div className="col col--4">

<br/>
<br/>

1. Add task type **LLM Get Embeddings**.
2. Choose the vector database & namespace.
3. Provide the input parameters.

</div>
<div className="col">
<div className="embed-loom-video">

<p><img src="/content/img/llm-get-embeddings-ui-method.png" alt="LLM Get Embeddings Task" width="500" height="auto"/></p>

</div>
</div>
</div>



</TabItem>
 <TabItem value="JSON" label="JSON Example">

```json
{
"name": "llm_generate_embeddings_task",
"taskReferenceName": "llm_generate_embeddings_task_ref",
"inputParameters": {
"llmProvider": "azure_openai",
"model": "text-davinci-003",
"text": "${workflow.input.text}"
},
"type": "LLM_GENERATE_EMBEDDINGS"
},
{
"name": "llm_get_embeddings_task",
"taskReferenceName": "llm_get_embeddings_task_ref",
"inputParameters": {
"vectorDB": "pineconedb",
"namespace": "myNewModel",
"index": "test",
"embeddings": "${llm_generate_embeddings_task_ref.output}"
},
"type": "LLM_GET_EMBEDDINGS"
}
],
"inputParameters": [
"text"
]
```
</TabItem>
</Tabs>