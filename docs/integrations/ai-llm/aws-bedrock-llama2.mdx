---
slug: "/integrations/ai-llm/aws-bedrock-llama2"
description: "Learn how to integrate AWS Bedrock Llama 3 with your Orkes Conductor cluster."
---

# AWS Bedrock Llama3 Integration with Orkes Conductor

To use system AI tasks in Orkes Conductor, you must integrate your Conductor cluster with the necessary AI/LLM providers. This guide explains how to integrate AWS Bedrock Llama3 with Orkes Conductor. Here’s an overview:

1. Get the required credentials from AWS Bedrock Llama3.
2. Configure a new AWS Bedrock Llama3 integration in Orkes Conductor.
3. Add models to the integration.
4. Set access limits to the AI model to govern which applications or groups can use them.

## Step 1: Get the AWS Bedrock Llama3 credentials

To integrate AWS Bedrock Llama3 with Orkes Conductor, retrieve the following credentials from your AWS account:

- [AWS account ID](https://docs.aws.amazon.com/accounts/latest/reference/manage-acct-identifiers.html#FindAccountId) and **region**
- (If assuming a role from another AWS account) [Amazon Resource Name (ARN)](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference-arns.html) and [External ID](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.html)
- (If the connection is established using the access key and secret from the AWS account) [Access key and secret from AWS account](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html).

## Step 2: Add an integration for AWS Bedrock Llama3

After obtaining the credentials, add an AWS Bedrock Llama3 integration to your Conductor cluster.

**To create an AWS Bedrock Llama3 integration:**

1. Go to **Integrations** from the left navigation menu on your Conductor cluster.
2. Select **+ New integration**.
3. In the **AI/LLM** section, choose **AWS Bedrock Llama3**.
4. Select **+ Add** and enter the following parameters:

| Parameters | Description | Required/Optional | 
| ---------- | ----------- | ----------------- | 
| Integration name | A name for the integration. | Required. | 
| Connection type | The connection type, depending upon how to establish the connection. Supported values:<ul><li>**Current Conductor Role**–Use the current Conductor role to establish the connection.</li><li>**Assume External Role**–Assume a role belonging to another AWS account to establish the connection. [Learn more](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.html).</li><li>**Access Key/Secret**–Establish the connection using the access key and secret.</li></ul> | Required. | 
| Region | The valid AWS region where the resource is located. For example, **us-east-1**. | Required. | 
| Account ID | The AWS account ID. | Optional. | 
| Role ARN | The Amazon Resource Name (ARN) to set up the connection. | Required if the _Connection Type_ is chosen as _Assume External Role_. | 
| External ID | The external ID that will assume the role, if applicable. [External ID](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.html) is used in an IAM role trust policy to designate the person who will assume the role. | Required if the _Connection Type_ is chosen as _Assume External Role_. | 
| Access key | The access key of the AWS account. | Required if the _Connection Type_ is chosen as _Access Key/Secret_. | 
| Access secret | The access secret of the AWS account. | Required if the _Connection Type_ is chosen as _Access Key/Secret_. | 
| Description | A description of your integration. | Required. | 

<p align="center"><img src="/content/img/create-new-aws-bedrock-llama3-integration.png" alt="AWS Bedrock Llama3 Integration with Orkes Conductor" width="60%" height="auto"></img></p>

5. (Optional) Toggle the **Active** button off if you don’t want to activate the integration instantly.
6. Select **Save**.

## Add AWS Bedrock Llama3 models

Once you’ve integrated AWS Bedrock Llama3, the next step is to configure specific models.

AWS Bedrock Llama3 has different models, such as Llama 3.2 1B Instruct, Llama 3.2 90B Instruct, and more, each designed for various use cases. Choose the model that best fits your use case.

**To add a model to the AWS Bedrock Llama3 integration:**

1. Go to the **Integrations** page and select the **+** button next to the integration created.

<p align="center"><img src="/content/img/create-new-aws-bedrock-llama3-integration-model-from-integrations-page.png" alt="Create AWS Bedrock Llama 2 Integration Model from Listed Integrations" width="100%" height="auto"></img></p>

2. Select **+ New model**.
3. Enter the **Model name** and a **Description**. Get the complete list of [AWS Bedrock Llama3 models](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html). 

<p align="center"><img src="/content/img/create-new-aws-bedrock-llama3-integration-model.png" alt="Create AWS Bedrock Llama 2 Integration Model" width="70%" height="auto"></img></p>

This saves the model for future use in AI tasks within Orkes Conductor.

## Step 4: Set access limit to integration

Once the integration is configured, set access controls to manage which applications or groups can use the models.

**To provide access to an application or group:**

1. Go to **Access Control** > **Applications** or **Groups** from the left navigation menu on your Conductor cluster.
2. Create a new group/application or select an existing one.
3. In the **Permissions** section, select **+ Add Permission**.
4. In the **Integration** tab, select the required AI models and toggle the necessary permissions.
5. Select **Add Permissions**. 

<p align="center"><img src="/content/img/rbac-aws-bedrock-llama3-integration.png" alt="Add Permissions for Integrations" width="70%" height="auto"></img></p>

The group or application can now access the AI model according to the configured permissions.

With the integration in place, you can now create workflows using [AI/LLM tasks](https://orkes.io/content/category/reference-docs/ai-tasks).

## More resources

- [Using AI Models or LLMs](https://orkes.io/content/developer-guides/using-llms-in-your-orkes-conductor-workflows)
- [Using Vector Databases](https://orkes.io/content/developer-guides/using-vector-databases-in-your-orkes-conductor-workflows)
- [Using AI Prompts](https://orkes.io/content/developer-guides/creating-and-managing-gen-ai-prompt-templates)
- [AI Orchestration Tutorials](https://orkes.io/content/developer-guides/quickstart-ai-orchestration)