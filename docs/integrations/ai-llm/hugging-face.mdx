---
slug: "/integrations/ai-llm/hugging-face"
description: "Learn how to integrate Hugging Face with your Orkes Conductor cluster."
---

# Hugging Face Integration with Orkes Conductor

To use system AI tasks in Orkes Conductor, you must integrate your Conductor cluster with the necessary AI/LLM providers. This guide explains how to integrate Hugging Face with Orkes Conductor. Here’s an overview:

1. Get the required credentials from Hugging Face.
2. Configure a new Hugging Face integration in Orkes Conductor.
3. Add models to the integration.
4. Set access limits to the AI model to govern which applications or groups can use them.

## Step 1: Get the Hugging Face credentials

To integrate Hugging Face with Orkes Conductor, retrieve the API token, namespace, and endpoint from the Hugging Face portal.

### Get the API token

**To get the API token:**

1. Sign in to the [Hugging Face](https://huggingface.co/) portal.
2. Select your account icon in the top-right corner and choose **Settings**.
3. Go to **Access Tokens** and select **+ Create new token**.

<p align="center"><img src="/content/img/view-api-keys-hf.png" alt="Get API Keys from Hugging Face platform" width="90%" height="auto"></img></p>

4. Enter a **Token name** and select **Create token**.
5. Copy and store the generated token.

### Get the namespace

**To get the namespace:**

Go to the account information icon from the top right corner and copy the namespace.
For example, the namespace is “johndoehf”.

<p align="center"><img src="/content/img/get-namespace.png" alt="Get Namespace from Hugging Face platform" width="50%" height="auto"></img></p>

### Create an endpoint

**To create the endpoint:**

1. Sign in to the [Hugging Face Inference Endpoints](https://endpoints.huggingface.co/).
2. [Create an endpoint](https://huggingface.co/docs/inference-endpoints/guides/create_endpoint) following the official Hugging Face documentation.

## Step 2: Add an integration for Hugging Face

After obtaining the credentials, add a Hugging Face integration to your Conductor cluster.

**To create a Hugging Face integration:**

1. Go to **Integrations** from the left navigation menu on your Conductor cluster.
2. Select **+ New integration**.
3. In the **AI/LLM** section, choose **Hugging Face**.
4. Select **+ Add** and enter the following parameters:

| Parameters | Description |
| ---------- | ----------- | 
| Integration name | A name for the integration. |
| API Key | The API token copied previously from the Hugging Face portal. |
| Namespace | The namespace of your Hugging Face account. |
| Description | A description of the integration. | 

<p align="center"><img src="/content/img/create-new-hugging-face-integration.png" alt="Hugging Face Integration with Orkes Conductor" width="60%" height="auto"></img></p>

5. (Optional) Toggle the **Active** button off if you don’t want to activate the integration instantly.
6. Select **Save**.

## Step 3: Add Hugging Facemodels

Once you’ve integrated Hugging Face, the next step is to configure specific models.

Hugging Face has different models, each designed for various use cases. Choose the model that best fits your use case.

**To add a model to the Hugging Face integration:**

1. Go to the **Integrations** page and select the **+** button next to the integration created.

<p align="center"><img src="/content/img/create-new-model-for-hugging-face-integration.png" alt="Create new model for Hugging Face Integration" width="100%" height="auto"></img></p>

2. Select **+ New model**.
3. Enter the **Model name**. Get the complete [list of Hugging Face models](https://huggingface.co/models). 
4. Select the **Endpoint** created previously and provide a **Description**. 

<p align="center"><img src="/content/img/creating-new-model-for-hugging-face-integration.png" alt="Creating new model for Hugging Face Integration" width="60%" height="auto"></img></p>

5. (Optional) Toggle the **Active** button off if you don’t want to activate the model instantly.
6. Select **Save**.

This saves the model for future use in AI tasks within Orkes Conductor.

## Step 4: Set access limit to integration

Once the integration is configured, set access controls to manage which applications or groups can use the models.

**To provide access to an application or group:**

1. Go to **Access Control** > **Applications** or **Groups** from the left navigation menu on your Conductor cluster.
2. Create a new group/application or select an existing one.
3. In the **Permissions** section, select **+ Add Permission**.
4. In the **Integration** tab, select the required AI models and toggle the necessary permissions.
5. Select **Add Permissions**. 

<p align="center"><img src="/content/img/add-integration-permission-for-hugging-face.png" alt="Add Permissions for Hugging Face Integration" width="70%" height="auto"></img></p>

The group or application can now access the AI model according to the configured permissions.

With the integration in place, you can now create workflows using [AI/LLM tasks](https://orkes.io/content/category/reference-docs/ai-tasks).

## More resources

- [Using AI Models or LLMs](https://orkes.io/content/developer-guides/using-llms-in-your-orkes-conductor-workflows)
- [Using Vector Databases](https://orkes.io/content/developer-guides/using-vector-databases-in-your-orkes-conductor-workflows)
- [Using AI Prompts](https://orkes.io/content/developer-guides/creating-and-managing-gen-ai-prompt-templates)
- [AI Orchestration Tutorials](https://orkes.io/content/developer-guides/quickstart-ai-orchestration)